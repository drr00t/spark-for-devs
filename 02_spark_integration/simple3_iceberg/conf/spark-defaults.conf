# spark.master                           spark://spark-master:7077
# spark.driver.memoryOverhead            400m 
# spark.executor.memory                  4g
# spark.executor.memoryOverhead          400m

# continuous running applications
# spark.scheduler.mode                    FAIR
# spark.scheduler.allocation.file         fairshceduler.xml

# app session deps
spark.jars.packages                    org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.spark:spark-hadoop-cloud_2.12:3.3.4,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262

# otimização de processamento específico da aplicação
# spark.files.maxPartitionBytes          10485760

# otimizações recomendadas
spark.serializer                            org.apache.spark.serializer.KryoSerializer
spark.sql.execution.arrow.pyspark.enabled   true

# enabling persistent logs
spark.eventLog.enabled                 true
spark.eventLog.dir                     /home/adriano/Arquivos/Projetos/spark-for-devs/01_spark_up_run/spark-logs


# s3a magic commiter 
spark.hadoop.fs.s3a.endpoint                                 http://192.168.15.9:9000
spark.hadoop.fs.s3a.connection.timeout                       6000
spark.hadoop.fs.s3a.impl                                     org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.committer.magic.enabled                  true
spark.hadoop.fs.s3a.committer.name                           magic
spark.hadoop.fs.s3a.committer.generate.uuid                  true
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a    org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory
spark.sql.sources.commitProtocolClass                        org.apache.spark.internal.io.cloud.PathOutputCommitProtocol
spark.sql.parquet.output.committer.class                     org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter

# minio catalog
spark.sql.extensions                                         org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.exploring                                  org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.exploring.type                             hadoop
spark.sql.catalog.exploring.warehouse                        s3a://spark-4devs/catalogs
spark.sql.catalog.sakila                                     org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.sakila.type                                hadoop
spark.sql.catalog.sakila.warehouse                           s3a://spark-4devs/catalogs
spark.sql.defaultCatalog                                     exploring
spark.sql.catalog.raw_data.default-namespace                 db

# spark.sql.catalog.exploring                                  org.apache.iceberg.spark.SparkCatalog
# spark.sql.catalog.exploring.type                             hadoop
# spark.sql.catalog.exploring.io-impl                          org.apache.iceberg.aws.s3.S3FileIO
# spark.sql.catalog.exploring.warehouse                        s3://spark-4devs/catalogs
# spark.sql.catalog.exploring.s3.endpoint                      http://192.168.15.7:9000